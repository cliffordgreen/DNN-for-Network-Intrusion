{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proposal for Deep Learning Approach to Network Intrusion Detection:\n",
    "\n",
    "### Evaluation of Generative Architecture Models vs Discriminative Architecture Models\n",
    "\n",
    "Basic DNN\n",
    "\n",
    "By-Cliff Green"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Here are some imports that are used along this notebook\n",
    "import math\n",
    "import itertools\n",
    "import pandas\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from time import time\n",
    "from collections import OrderedDict\n",
    "import glob\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "train20_nsl_kdd_dataset_path = \"NSL-KDD-Dataset-master/NSL-KDD-Dataset-master/KDDTrain+_20Percent.txt\"\n",
    "train_nsl_kdd_dataset_path = \"NSL-KDD-Dataset-master/NSL-KDD-Dataset-master/KDDTrain+.txt\"\n",
    "test_nsl_kdd_dataset_path = \"NSL-KDD-Dataset-master/NSL-KDD-Dataset-master/KDDTest-21.txt\"\n",
    "\n",
    "\n",
    "col_names = np.array([\"duration\",\"protocol_type\",\"service\",\"flag\",\"src_bytes\",\n",
    "    \"dst_bytes\",\"land\",\"wrong_fragment\",\"urgent\",\"hot\",\"num_failed_logins\",\n",
    "    \"logged_in\",\"num_compromised\",\"root_shell\",\"su_attempted\",\"num_root\",\n",
    "    \"num_file_creations\",\"num_shells\",\"num_access_files\",\"num_outbound_cmds\",\n",
    "    \"is_host_login\",\"is_guest_login\",\"count\",\"srv_count\",\"serror_rate\",\n",
    "    \"srv_serror_rate\",\"rerror_rate\",\"srv_rerror_rate\",\"same_srv_rate\",\n",
    "    \"diff_srv_rate\",\"srv_diff_host_rate\",\"dst_host_count\",\"dst_host_srv_count\",\n",
    "    \"dst_host_same_srv_rate\",\"dst_host_diff_srv_rate\",\"dst_host_same_src_port_rate\",\n",
    "    \"dst_host_srv_diff_host_rate\",\"dst_host_serror_rate\",\"dst_host_srv_serror_rate\",\n",
    "    \"dst_host_rerror_rate\",\"dst_host_srv_rerror_rate\",\"labels\",\"attrib43\"])\n",
    "\n",
    "\n",
    "attack_dict = {\n",
    "    'normal': 'normal',\n",
    "    \n",
    "    'back': 'DoS',\n",
    "    'land': 'DoS',\n",
    "    'neptune': 'DoS',\n",
    "    'pod': 'DoS',\n",
    "    'smurf': 'DoS',\n",
    "    'teardrop': 'DoS',\n",
    "    'mailbomb': 'DoS',\n",
    "    'apache2': 'DoS',\n",
    "    'processtable': 'DoS',\n",
    "    'udpstorm': 'DoS',\n",
    "    \n",
    "    'ipsweep': 'Probe',\n",
    "    'nmap': 'Probe',\n",
    "    'portsweep': 'Probe',\n",
    "    'satan': 'Probe',\n",
    "    'mscan': 'Probe',\n",
    "    'saint': 'Probe',\n",
    "\n",
    "    'ftp_write': 'R2L',\n",
    "    'guess_passwd': 'R2L',\n",
    "    'imap': 'R2L',\n",
    "    'multihop': 'R2L',\n",
    "    'phf': 'R2L',\n",
    "    'spy': 'R2L',\n",
    "    'warezclient': 'R2L',\n",
    "    'warezmaster': 'R2L',\n",
    "    'sendmail': 'R2L',\n",
    "    'named': 'R2L',\n",
    "    'snmpgetattack': 'R2L',\n",
    "    'snmpguess': 'R2L',\n",
    "    'xlock': 'R2L',\n",
    "    'xsnoop': 'R2L',\n",
    "    'worm': 'R2L',\n",
    "    \n",
    "    'buffer_overflow': 'U2R',\n",
    "    'loadmodule': 'U2R',\n",
    "    'perl': 'U2R',\n",
    "    'rootkit': 'U2R',\n",
    "    'httptunnel': 'U2R',\n",
    "    'ps': 'U2R',    \n",
    "    'sqlattack': 'U2R',\n",
    "    'xterm': 'U2R'\n",
    "}\n",
    "\n",
    "\n",
    "# In[3]:\n",
    "\n",
    "\n",
    "def _label2(x):\n",
    "    if x['labels'] == 'normal':\n",
    "        return 'normal'\n",
    "    else:\n",
    "        return 'attack'\n",
    "\n",
    "def returnvalue(x):\n",
    "    return attack_dict.get(x['labels'])\n",
    "\n",
    "\n",
    "df_kdd_dataset_train = pd.read_csv(train_nsl_kdd_dataset_path, index_col=None, header=0, names=col_names)\n",
    "df_kdd_dataset_test = pd.read_csv(test_nsl_kdd_dataset_path, index_col=None, header=0, names=col_names)\n",
    "\n",
    "df_kdd_dataset_train['label2'] = df_kdd_dataset_train.apply(_label2,axis=1)\n",
    "df_kdd_dataset_train['label3'] = df_kdd_dataset_train.apply(returnvalue,axis=1)\n",
    "\n",
    "df_kdd_dataset_test['label2'] = df_kdd_dataset_test.apply(_label2,axis=1)\n",
    "df_kdd_dataset_test['label3'] = df_kdd_dataset_test.apply(returnvalue,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_kdd_dataset_train = df_kdd_dataset_train.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_kdd_dataset_train.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_kdd_dataset_train['protocol_type'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [],
   "source": [
    "#col_names[binary_inx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nominal_inx = [1, 2, 3]\n",
    "binary_inx = [6, 11, 13, 14, 20, 21]\n",
    "numeric_inx = list(set(range(41)).difference(nominal_inx).difference(binary_inx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_inx = [0,\n",
    " 4,\n",
    " 5,\n",
    " 7,\n",
    " 8,\n",
    " 9,\n",
    " 10,\n",
    " 12,\n",
    " 15,\n",
    " 16,\n",
    " 17,\n",
    " 18,\n",
    " 22,\n",
    " 23,\n",
    " 24,\n",
    " 25,\n",
    " 26,\n",
    " 27,\n",
    " 28,\n",
    " 29,\n",
    " 30,\n",
    " 31,\n",
    " 32,\n",
    " 33,\n",
    " 34,\n",
    " 35,\n",
    " 36,\n",
    " 37,\n",
    " 38,\n",
    " 39,\n",
    " 40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "catagorical_inx = [1, 2, 3, 6, 11, 13, 14, 20, 21]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cols_to_norm = col_names[numeric_inx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kdd_dataset_train[cols_to_norm] = df_kdd_dataset_train[cols_to_norm].apply(lambda x: (x-x.min())/(x.max()-x.min() ))\n",
    "df_kdd_dataset_test[cols_to_norm] = df_kdd_dataset_test[cols_to_norm].apply(lambda x: (x-x.min())/(x.max()-x.min() ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "Numeric = []\n",
    "for i in numeric_inx+binary_inx:\n",
    "    #print(i)\n",
    "    i = tf.feature_column.numeric_column(col_names[i])\n",
    "    Numeric.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_kdd_dataset_train[col_names[1]].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nominal = []\n",
    "for i in nominal_inx: \n",
    "    i = tf.feature_column.categorical_column_with_hash_bucket(col_names[i],hash_bucket_size=len(df_kdd_dataset_train[col_names[i]].unique()))\n",
    "    Nominal.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#assign_group = tf.feature_column.categorical_column_with_vocabulary_list('Group', ['A', 'B', 'C', 'D'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#assign_group = tf.feature_column.categorical_column_with_hash_bucket('Group', hash_bucket_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#making buckets for age varaible\n",
    "#age_bucket = tf.feature_column.bucketized_column(age, boundaries=[20,30,40,50,60,70,80])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feat_cols = Nominal+Numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_kdd_dataset_train.drop(['labels','attrib43','label2','label3','num_outbound_cmds'], axis = 1)\n",
    "\n",
    "X_test = df_kdd_dataset_test.drop(['labels','attrib43','label2','label3','num_outbound_cmds'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train = df_kdd_dataset_train['label3']\n",
    "\n",
    "y_test = df_kdd_dataset_test['label3']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(['normal', 'DoS','Probe', 'R2L','U2R'])\n",
    "y_train = le.transform(y_train)\n",
    "y_test = le.transform(y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = pd.DataFrame(y_test)\n",
    "y_train = pd.DataFrame(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#X_train, X_test, y_train, y_test = train_test_split(x_data, labels,  test_size = .3, random_state = 101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17633, 40)"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_func = tf.estimator.inputs.pandas_input_fn(x=X_train, y=y_train, batch_size=100, num_epochs=1000, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shallow Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\Green\\AppData\\Local\\Temp\\tmpnritn_33\n",
      "INFO:tensorflow:Using config: {'_tf_random_seed': 1, '_save_summary_steps': 100, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_keep_checkpoint_max': 5, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_model_dir': 'C:\\\\Users\\\\Green\\\\AppData\\\\Local\\\\Temp\\\\tmpnritn_33', '_session_config': None}\n"
     ]
    }
   ],
   "source": [
    "model = tf.estimator.LinearClassifier(feature_columns=feat_cols, n_classes=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into C:\\Users\\Green\\AppData\\Local\\Temp\\tmpnritn_33\\model.ckpt.\n",
      "INFO:tensorflow:step = 1, loss = 179.176\n",
      "INFO:tensorflow:global_step/sec: 172.841\n",
      "INFO:tensorflow:step = 101, loss = 13.5142 (0.580 sec)\n",
      "INFO:tensorflow:global_step/sec: 244.464\n",
      "INFO:tensorflow:step = 201, loss = 21.7895 (0.410 sec)\n",
      "INFO:tensorflow:global_step/sec: 212.652\n",
      "INFO:tensorflow:step = 301, loss = 8.89953 (0.470 sec)\n",
      "INFO:tensorflow:global_step/sec: 185.37\n",
      "INFO:tensorflow:step = 401, loss = 5.72815 (0.538 sec)\n",
      "INFO:tensorflow:global_step/sec: 246.884\n",
      "INFO:tensorflow:step = 501, loss = 6.27231 (0.405 sec)\n",
      "INFO:tensorflow:global_step/sec: 232.459\n",
      "INFO:tensorflow:step = 601, loss = 8.68018 (0.430 sec)\n",
      "INFO:tensorflow:global_step/sec: 245.674\n",
      "INFO:tensorflow:step = 701, loss = 3.76325 (0.407 sec)\n",
      "INFO:tensorflow:global_step/sec: 239.17\n",
      "INFO:tensorflow:step = 801, loss = 4.85086 (0.418 sec)\n",
      "INFO:tensorflow:global_step/sec: 235.764\n",
      "INFO:tensorflow:step = 901, loss = 5.69181 (0.424 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1000 into C:\\Users\\Green\\AppData\\Local\\Temp\\tmpnritn_33\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 3.82577.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.canned.linear.LinearClassifier at 0x12ad5e3d0b8>"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train(input_fn=input_func, steps = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "eval_input_func = tf.estimator.inputs.pandas_input_fn(x=X_test, y=y_test, batch_size=10, num_epochs=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Starting evaluation at 2017-09-28-22:15:27\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\Green\\AppData\\Local\\Temp\\tmpnritn_33\\model.ckpt-1000\n",
      "INFO:tensorflow:Finished evaluation at 2017-09-28-22:15:31\n",
      "INFO:tensorflow:Saving dict for global step 1000: accuracy = 0.524854, average_loss = 2.32314, global_step = 1000, loss = 23.2294\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(eval_input_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.52485442,\n",
       " 'average_loss': 2.323139,\n",
       " 'global_step': 1000,\n",
       " 'loss': 23.229429}"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_input_func = tf.estimator.inputs.pandas_input_fn(x = X_test, batch_size=10,num_epochs=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = model.predict(pred_input_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We must go deeper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[_EmbeddingColumn(categorical_column=_HashedCategoricalColumn(key='protocol_type', hash_bucket_size=3, dtype=tf.string), dimension=3, combiner='mean', initializer=<tensorflow.python.ops.init_ops.TruncatedNormal object at 0x0000012AC9ADB588>, ckpt_to_load_from=None, tensor_name_in_ckpt=None, max_norm=None, trainable=True),\n",
       " _EmbeddingColumn(categorical_column=_HashedCategoricalColumn(key='service', hash_bucket_size=66, dtype=tf.string), dimension=66, combiner='mean', initializer=<tensorflow.python.ops.init_ops.TruncatedNormal object at 0x0000012AC9ADB0F0>, ckpt_to_load_from=None, tensor_name_in_ckpt=None, max_norm=None, trainable=True),\n",
       " _EmbeddingColumn(categorical_column=_HashedCategoricalColumn(key='flag', hash_bucket_size=11, dtype=tf.string), dimension=11, combiner='mean', initializer=<tensorflow.python.ops.init_ops.TruncatedNormal object at 0x0000012AC9ADBE48>, ckpt_to_load_from=None, tensor_name_in_ckpt=None, max_norm=None, trainable=True)]"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#for catagory columns\n",
    "size = [3,66,11]\n",
    "\n",
    "emb_Nominal = []\n",
    "for j in range(len(Nominal)):\n",
    "    emb_Nominal.append(tf.feature_column.embedding_column(Nominal[j], dimension=size[j]))\n",
    "\n",
    "emb_Nominal    \n",
    "#embedded_service = tf.feature_column.embedding_column(service, dimension=66)\n",
    "#embedded_flag = tf.feature_column.embedding_column(flag, dimension=11)\n",
    "\n",
    "#embed_nominal = [embedded_pt,embedded_service,embedded_flag ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feat_cols = emb_Nominal + Numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_func = tf.estimator.inputs.pandas_input_fn(X_train, y_train, batch_size=10, num_epochs=1000, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\Green\\AppData\\Local\\Temp\\tmpp14cy7u7\n",
      "INFO:tensorflow:Using config: {'_tf_random_seed': 1, '_save_summary_steps': 100, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_keep_checkpoint_max': 5, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_model_dir': 'C:\\\\Users\\\\Green\\\\AppData\\\\Local\\\\Temp\\\\tmpp14cy7u7', '_session_config': None}\n"
     ]
    }
   ],
   "source": [
    "dnn_model = tf.estimator.DNNClassifier(hidden_units=[40,100,10], feature_columns=feat_cols, n_classes=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\Green\\AppData\\Local\\Temp\\tmpp14cy7u7\\model.ckpt-1000\n",
      "INFO:tensorflow:Saving checkpoints for 1001 into C:\\Users\\Green\\AppData\\Local\\Temp\\tmpp14cy7u7\\model.ckpt.\n",
      "INFO:tensorflow:step = 1001, loss = 0.120365\n",
      "INFO:tensorflow:global_step/sec: 312.654\n",
      "INFO:tensorflow:step = 1101, loss = 0.117332 (0.324 sec)\n",
      "INFO:tensorflow:global_step/sec: 317.62\n",
      "INFO:tensorflow:step = 1201, loss = 0.163696 (0.315 sec)\n",
      "INFO:tensorflow:global_step/sec: 340.39\n",
      "INFO:tensorflow:step = 1301, loss = 0.0819727 (0.291 sec)\n",
      "INFO:tensorflow:global_step/sec: 308.779\n",
      "INFO:tensorflow:step = 1401, loss = 0.18231 (0.326 sec)\n",
      "INFO:tensorflow:global_step/sec: 361.39\n",
      "INFO:tensorflow:step = 1501, loss = 0.232271 (0.278 sec)\n",
      "INFO:tensorflow:global_step/sec: 342.731\n",
      "INFO:tensorflow:step = 1601, loss = 0.0479929 (0.291 sec)\n",
      "INFO:tensorflow:global_step/sec: 349.904\n",
      "INFO:tensorflow:step = 1701, loss = 0.277765 (0.287 sec)\n",
      "INFO:tensorflow:global_step/sec: 347.546\n",
      "INFO:tensorflow:step = 1801, loss = 0.674632 (0.287 sec)\n",
      "INFO:tensorflow:global_step/sec: 349.944\n",
      "INFO:tensorflow:step = 1901, loss = 0.261073 (0.286 sec)\n",
      "INFO:tensorflow:global_step/sec: 348.721\n",
      "INFO:tensorflow:step = 2001, loss = 0.240863 (0.287 sec)\n",
      "INFO:tensorflow:global_step/sec: 360.015\n",
      "INFO:tensorflow:step = 2101, loss = 0.0961032 (0.278 sec)\n",
      "INFO:tensorflow:global_step/sec: 352.453\n",
      "INFO:tensorflow:step = 2201, loss = 0.121923 (0.284 sec)\n",
      "INFO:tensorflow:global_step/sec: 332.417\n",
      "INFO:tensorflow:step = 2301, loss = 0.817194 (0.301 sec)\n",
      "INFO:tensorflow:global_step/sec: 356.217\n",
      "INFO:tensorflow:step = 2401, loss = 0.33536 (0.281 sec)\n",
      "INFO:tensorflow:global_step/sec: 360.063\n",
      "INFO:tensorflow:step = 2501, loss = 0.0583098 (0.278 sec)\n",
      "INFO:tensorflow:global_step/sec: 356.154\n",
      "INFO:tensorflow:step = 2601, loss = 0.476226 (0.283 sec)\n",
      "INFO:tensorflow:global_step/sec: 360.091\n",
      "INFO:tensorflow:step = 2701, loss = 0.113424 (0.276 sec)\n",
      "INFO:tensorflow:global_step/sec: 346.299\n",
      "INFO:tensorflow:step = 2801, loss = 0.0218085 (0.290 sec)\n",
      "INFO:tensorflow:global_step/sec: 335.805\n",
      "INFO:tensorflow:step = 2901, loss = 0.0283752 (0.297 sec)\n",
      "INFO:tensorflow:global_step/sec: 352.359\n",
      "INFO:tensorflow:step = 3001, loss = 0.0608319 (0.285 sec)\n",
      "INFO:tensorflow:global_step/sec: 335.808\n",
      "INFO:tensorflow:step = 3101, loss = 0.0159847 (0.298 sec)\n",
      "INFO:tensorflow:global_step/sec: 342.729\n",
      "INFO:tensorflow:step = 3201, loss = 0.516529 (0.292 sec)\n",
      "INFO:tensorflow:global_step/sec: 361.353\n",
      "INFO:tensorflow:step = 3301, loss = 0.544137 (0.277 sec)\n",
      "INFO:tensorflow:global_step/sec: 365.328\n",
      "INFO:tensorflow:step = 3401, loss = 0.726524 (0.274 sec)\n",
      "INFO:tensorflow:global_step/sec: 320.656\n",
      "INFO:tensorflow:step = 3501, loss = 0.100503 (0.312 sec)\n",
      "INFO:tensorflow:global_step/sec: 357.478\n",
      "INFO:tensorflow:step = 3601, loss = 0.0510661 (0.280 sec)\n",
      "INFO:tensorflow:global_step/sec: 357.467\n",
      "INFO:tensorflow:step = 3701, loss = 0.0827406 (0.279 sec)\n",
      "INFO:tensorflow:global_step/sec: 336.972\n",
      "INFO:tensorflow:step = 3801, loss = 0.0019588 (0.298 sec)\n",
      "INFO:tensorflow:global_step/sec: 325.93\n",
      "INFO:tensorflow:step = 3901, loss = 0.0219649 (0.306 sec)\n",
      "INFO:tensorflow:global_step/sec: 372.098\n",
      "INFO:tensorflow:step = 4001, loss = 0.107133 (0.272 sec)\n",
      "INFO:tensorflow:global_step/sec: 360.092\n",
      "INFO:tensorflow:step = 4101, loss = 0.0338428 (0.275 sec)\n",
      "INFO:tensorflow:global_step/sec: 347.468\n",
      "INFO:tensorflow:step = 4201, loss = 0.276672 (0.289 sec)\n",
      "INFO:tensorflow:global_step/sec: 330.251\n",
      "INFO:tensorflow:step = 4301, loss = 0.107857 (0.302 sec)\n",
      "INFO:tensorflow:global_step/sec: 293.335\n",
      "INFO:tensorflow:step = 4401, loss = 0.0588889 (0.339 sec)\n",
      "INFO:tensorflow:global_step/sec: 362.669\n",
      "INFO:tensorflow:step = 4501, loss = 5.332 (0.279 sec)\n",
      "INFO:tensorflow:global_step/sec: 316.618\n",
      "INFO:tensorflow:step = 4601, loss = 0.0169896 (0.315 sec)\n",
      "INFO:tensorflow:global_step/sec: 352.415\n",
      "INFO:tensorflow:step = 4701, loss = 0.00610225 (0.284 sec)\n",
      "INFO:tensorflow:global_step/sec: 363.994\n",
      "INFO:tensorflow:step = 4801, loss = 0.231748 (0.276 sec)\n",
      "INFO:tensorflow:global_step/sec: 345.134\n",
      "INFO:tensorflow:step = 4901, loss = 3.04513 (0.290 sec)\n",
      "INFO:tensorflow:global_step/sec: 360.014\n",
      "INFO:tensorflow:step = 5001, loss = 0.232956 (0.277 sec)\n",
      "INFO:tensorflow:global_step/sec: 365.365\n",
      "INFO:tensorflow:step = 5101, loss = 0.00488478 (0.275 sec)\n",
      "INFO:tensorflow:global_step/sec: 361.318\n",
      "INFO:tensorflow:step = 5201, loss = 0.0210275 (0.277 sec)\n",
      "INFO:tensorflow:global_step/sec: 334.71\n",
      "INFO:tensorflow:step = 5301, loss = 0.46689 (0.299 sec)\n",
      "INFO:tensorflow:global_step/sec: 340.358\n",
      "INFO:tensorflow:step = 5401, loss = 0.170739 (0.293 sec)\n",
      "INFO:tensorflow:global_step/sec: 357.471\n",
      "INFO:tensorflow:step = 5501, loss = 0.439198 (0.280 sec)\n",
      "INFO:tensorflow:global_step/sec: 361.356\n",
      "INFO:tensorflow:step = 5601, loss = 0.207726 (0.278 sec)\n",
      "INFO:tensorflow:global_step/sec: 351.21\n",
      "INFO:tensorflow:step = 5701, loss = 0.0499044 (0.284 sec)\n",
      "INFO:tensorflow:global_step/sec: 345.069\n",
      "INFO:tensorflow:step = 5801, loss = 0.111166 (0.290 sec)\n",
      "INFO:tensorflow:global_step/sec: 333.588\n",
      "INFO:tensorflow:step = 5901, loss = 0.281853 (0.301 sec)\n",
      "INFO:tensorflow:global_step/sec: 356.192\n",
      "INFO:tensorflow:step = 6001, loss = 0.16039 (0.281 sec)\n",
      "INFO:tensorflow:global_step/sec: 345.069\n",
      "INFO:tensorflow:step = 6101, loss = 0.383093 (0.290 sec)\n",
      "INFO:tensorflow:global_step/sec: 365.328\n",
      "INFO:tensorflow:step = 6201, loss = 0.00758045 (0.273 sec)\n",
      "INFO:tensorflow:global_step/sec: 352.417\n",
      "INFO:tensorflow:step = 6301, loss = 0.0213172 (0.285 sec)\n",
      "INFO:tensorflow:global_step/sec: 345.039\n",
      "INFO:tensorflow:step = 6401, loss = 0.0178985 (0.289 sec)\n",
      "INFO:tensorflow:global_step/sec: 346.33\n",
      "INFO:tensorflow:step = 6501, loss = 0.165319 (0.290 sec)\n",
      "INFO:tensorflow:global_step/sec: 332.417\n",
      "INFO:tensorflow:step = 6601, loss = 0.0846865 (0.300 sec)\n",
      "INFO:tensorflow:global_step/sec: 345.136\n",
      "INFO:tensorflow:step = 6701, loss = 0.0212607 (0.290 sec)\n",
      "INFO:tensorflow:global_step/sec: 356.159\n",
      "INFO:tensorflow:step = 6801, loss = 0.0343393 (0.282 sec)\n",
      "INFO:tensorflow:global_step/sec: 364.029\n",
      "INFO:tensorflow:step = 6901, loss = 0.167552 (0.274 sec)\n",
      "INFO:tensorflow:global_step/sec: 363.957\n",
      "INFO:tensorflow:step = 7001, loss = 0.0074592 (0.275 sec)\n",
      "INFO:tensorflow:global_step/sec: 338.082\n",
      "INFO:tensorflow:step = 7101, loss = 0.343431 (0.297 sec)\n",
      "INFO:tensorflow:global_step/sec: 357.47\n",
      "INFO:tensorflow:step = 7201, loss = 0.559989 (0.280 sec)\n",
      "INFO:tensorflow:global_step/sec: 348.721\n",
      "INFO:tensorflow:step = 7301, loss = 0.0490432 (0.287 sec)\n",
      "INFO:tensorflow:global_step/sec: 325.928\n",
      "INFO:tensorflow:step = 7401, loss = 0.0730294 (0.306 sec)\n",
      "INFO:tensorflow:global_step/sec: 343.912\n",
      "INFO:tensorflow:step = 7501, loss = 0.0018314 (0.290 sec)\n",
      "INFO:tensorflow:global_step/sec: 329.183\n",
      "INFO:tensorflow:step = 7601, loss = 0.0124444 (0.306 sec)\n",
      "INFO:tensorflow:global_step/sec: 358.719\n",
      "INFO:tensorflow:step = 7701, loss = 0.0405676 (0.279 sec)\n",
      "INFO:tensorflow:global_step/sec: 362.674\n",
      "INFO:tensorflow:step = 7801, loss = 0.00291259 (0.276 sec)\n",
      "INFO:tensorflow:global_step/sec: 351.175\n",
      "INFO:tensorflow:step = 7901, loss = 0.347051 (0.285 sec)\n",
      "INFO:tensorflow:global_step/sec: 360.065\n",
      "INFO:tensorflow:step = 8001, loss = 0.227074 (0.277 sec)\n",
      "INFO:tensorflow:global_step/sec: 362.657\n",
      "INFO:tensorflow:step = 8101, loss = 0.439876 (0.276 sec)\n",
      "INFO:tensorflow:global_step/sec: 352.416\n",
      "INFO:tensorflow:step = 8201, loss = 1.14407 (0.285 sec)\n",
      "INFO:tensorflow:global_step/sec: 361.389\n",
      "INFO:tensorflow:step = 8301, loss = 0.337501 (0.276 sec)\n",
      "INFO:tensorflow:global_step/sec: 357.434\n",
      "INFO:tensorflow:step = 8401, loss = 0.603383 (0.280 sec)\n",
      "INFO:tensorflow:global_step/sec: 358.795\n",
      "INFO:tensorflow:step = 8501, loss = 0.352331 (0.280 sec)\n",
      "INFO:tensorflow:global_step/sec: 361.314\n",
      "INFO:tensorflow:step = 8601, loss = 0.206674 (0.277 sec)\n",
      "INFO:tensorflow:global_step/sec: 362.669\n",
      "INFO:tensorflow:step = 8701, loss = 0.0221276 (0.278 sec)\n",
      "INFO:tensorflow:global_step/sec: 366.677\n",
      "INFO:tensorflow:step = 8801, loss = 0.0751633 (0.270 sec)\n",
      "INFO:tensorflow:global_step/sec: 365.363\n",
      "INFO:tensorflow:step = 8901, loss = 0.0319816 (0.275 sec)\n",
      "INFO:tensorflow:global_step/sec: 363.958\n",
      "INFO:tensorflow:step = 9001, loss = 0.405121 (0.275 sec)\n",
      "INFO:tensorflow:global_step/sec: 348.714\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:step = 9101, loss = 0.00384744 (0.289 sec)\n",
      "INFO:tensorflow:global_step/sec: 372.15\n",
      "INFO:tensorflow:step = 9201, loss = 0.0676948 (0.266 sec)\n",
      "INFO:tensorflow:global_step/sec: 331.341\n",
      "INFO:tensorflow:step = 9301, loss = 0.00133501 (0.303 sec)\n",
      "INFO:tensorflow:global_step/sec: 325.928\n",
      "INFO:tensorflow:step = 9401, loss = 0.0560638 (0.306 sec)\n",
      "INFO:tensorflow:global_step/sec: 346.298\n",
      "INFO:tensorflow:step = 9501, loss = 0.108389 (0.289 sec)\n",
      "INFO:tensorflow:global_step/sec: 356.188\n",
      "INFO:tensorflow:step = 9601, loss = 0.00830353 (0.282 sec)\n",
      "INFO:tensorflow:global_step/sec: 362.714\n",
      "INFO:tensorflow:step = 9701, loss = 0.0985334 (0.275 sec)\n",
      "INFO:tensorflow:global_step/sec: 362.635\n",
      "INFO:tensorflow:step = 9801, loss = 0.832755 (0.277 sec)\n",
      "INFO:tensorflow:global_step/sec: 349.942\n",
      "INFO:tensorflow:step = 9901, loss = 0.0597359 (0.283 sec)\n",
      "INFO:tensorflow:global_step/sec: 346.301\n",
      "INFO:tensorflow:step = 10001, loss = 0.0106158 (0.291 sec)\n",
      "INFO:tensorflow:global_step/sec: 312.643\n",
      "INFO:tensorflow:step = 10101, loss = 3.39755 (0.321 sec)\n",
      "INFO:tensorflow:global_step/sec: 360.055\n",
      "INFO:tensorflow:step = 10201, loss = 0.00933394 (0.278 sec)\n",
      "INFO:tensorflow:global_step/sec: 365.324\n",
      "INFO:tensorflow:step = 10301, loss = 0.00650295 (0.273 sec)\n",
      "INFO:tensorflow:global_step/sec: 349.946\n",
      "INFO:tensorflow:step = 10401, loss = 0.0237198 (0.286 sec)\n",
      "INFO:tensorflow:global_step/sec: 348.716\n",
      "INFO:tensorflow:step = 10501, loss = 0.762347 (0.288 sec)\n",
      "INFO:tensorflow:global_step/sec: 319.665\n",
      "INFO:tensorflow:step = 10601, loss = 0.0152563 (0.313 sec)\n",
      "INFO:tensorflow:global_step/sec: 354.926\n",
      "INFO:tensorflow:step = 10701, loss = 0.102227 (0.281 sec)\n",
      "INFO:tensorflow:global_step/sec: 357.463\n",
      "INFO:tensorflow:step = 10801, loss = 0.0133081 (0.281 sec)\n",
      "INFO:tensorflow:global_step/sec: 370.756\n",
      "INFO:tensorflow:step = 10901, loss = 0.0347047 (0.269 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 11000 into C:\\Users\\Green\\AppData\\Local\\Temp\\tmpp14cy7u7\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.400717.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.canned.dnn.DNNClassifier at 0x12ad4374898>"
      ]
     },
     "execution_count": 344,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dnn_model.train(input_fn=input_func, steps=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "eval_input_func = tf.estimator.inputs.pandas_input_fn(x = X_train, y=y_train, batch_size=100, num_epochs=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Starting evaluation at 2017-09-28-22:24:08\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\Green\\AppData\\Local\\Temp\\tmpp14cy7u7\\model.ckpt-11000\n",
      "INFO:tensorflow:Finished evaluation at 2017-09-28-22:24:14\n",
      "INFO:tensorflow:Saving dict for global step 11000: accuracy = 0.988783, average_loss = 0.0322011, global_step = 11000, loss = 3.21939\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.98878324,\n",
       " 'average_loss': 0.032201067,\n",
       " 'global_step': 11000,\n",
       " 'loss': 3.2193909}"
      ]
     },
     "execution_count": 346,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dnn_model.evaluate(eval_input_func)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "eval_input_func = tf.estimator.inputs.pandas_input_fn(x = X_test, y=y_test, batch_size=100, num_epochs=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Starting evaluation at 2017-09-28-22:24:15\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\Green\\AppData\\Local\\Temp\\tmpp14cy7u7\\model.ckpt-11000\n",
      "INFO:tensorflow:Finished evaluation at 2017-09-28-22:24:16\n",
      "INFO:tensorflow:Saving dict for global step 11000: accuracy = 0.556503, average_loss = 2.73515, global_step = 11000, loss = 272.343\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.55650264,\n",
       " 'average_loss': 2.7351542,\n",
       " 'global_step': 11000,\n",
       " 'loss': 272.3432}"
      ]
     },
     "execution_count": 348,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dnn_model.evaluate(eval_input_func)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### bad, lets try other models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
